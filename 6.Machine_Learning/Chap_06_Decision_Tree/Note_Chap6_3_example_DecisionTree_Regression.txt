Decision Tree _ Regression task example

Assuming a training dataset like this

House  Size (sq ft)  Age (years)  Price ($1000s)
1      1500         10           200
2      2000         5            300
3      1300         15           170
4      1800         8            240
5      2200         3            320
6      1600         12           210


#--------------------------------------------------------------------------------------------------#
#------------------- Step 1: Calculate the initial variance (before any splits) -------------------#
#--------------------------------------------------------------------------------------------------#

Step 1: Calculate the initial variance (before any splits)

The mean price of all houses is: (200 + 300 + 170 + 240 + 320 + 210) / 6 = 240

Variance calculation:
(200 - 240)^2 + (300 - 240)^2 + (170 - 240)^2 + (240 - 240)^2 + (320 - 240)^2 + (210 - 240)^2
= 1600        + 3600          + 4900          + 0             + 6400          + 900 
= 17400

Variance = 17400 / 6 = 2900

#----------------------------------------------------------------------------------#
#----------------------- Step 2: Find the best split-------------------------------#
#----------------------------------------------------------------------------------#

Step 2: Find the best split

We need to evaluate potential splits on each feature to find the one that reduces variance the most.

-------------------------
Potential Split on Size (sq ft)

Let's try splitting at 1700 sq ft:
	
	Left Group (Size < 1700 sq ft): Houses 1, 3, 6
	Mean price: (200 + 170 + 210) / 3 = 193.33
	Variance: ((200 - 193.33)^2 + (170 - 193.33)^2 + (210 - 193.33)^2) / 3 = 280.67


	Right Group (Size ≥ 1700 sq ft): Houses 2, 4, 5
	Mean price: (300 + 240 + 320) / 3 = 286.67
	Variance: ((300 - 286.67)^2 + (240 - 286.67)^2 + (320 - 286.67)²) / 3 = 1066.67

Weighted variance after split = (3/6) × 280.67 + (3/6) × 1066.67 = 673.67

Variance reduction = 2900 - 673.67 = 2226.33

---------------------------------------
Potential Split on Age (years)

	Let's try splitting at 9 years:
	Left Group (Age < 9 years): Houses 2, 4, 5
	Mean price: (300 + 240 + 320) / 3 = 286.67
	Variance: ((300 - 286.67)^2 + (240 - 286.67)^2 + (320 - 286.67)^2) / 3 = 1066.67


	Right Group (Age ≥ 9 years): Houses 1, 3, 6
	Mean price: (200 + 170 + 210) / 3 = 193.33
	Variance: ((200 - 193.33)^2 + (170 - 193.33)^2 + (210 - 193.33)^2) / 3 = 280.67

Weighted variance after split = (3/6) × 1066.67 + (3/6) × 280.67 = 673.67

Variance reduction = 2900 - 673.67 = 2226.33

----------------------------------------
Both splits yield the same variance reduction in this simple example (which is common in small datasets), so let's choose the Size feature for the first split.



#---------------------------------------------------------------------------------------------#
#----------------------- Step 3: Create the first split node ---------------------------------#
#---------------------------------------------------------------------------------------------#

Step 3: Create the first split node

Our decision tree now has its first split:
	If Size < 1700 sq ft, go left
	If Size ≥ 1700 sq ft, go right

Left Node: Houses 1, 3, 6 (mean price = $193,330)
Right Node: Houses 2, 4, 5 (mean price = $286,670)


#------------------------------------------------------------------------------------------------#
#----------------------- Step 4: Continue splitting recursively ---------------------------------#
#------------------------------------------------------------------------------------------------#

Step 4: Continue splitting recursively


Let's split the left node (Houses 1, 3, 6) further.
-----------------------------

Potential Split on Age within the left node

Let's try splitting at 11 years:
	Left-Left Group (Size < 1700 sq ft AND Age < 11 years): House 1
	Mean price: 200
	Variance: 0 (only one data point)

	Left-Right Group (Size < 1700 sq ft AND Age ≥ 11 years): Houses 3, 6
	Mean price: (170 + 210) / 2 = 190
	Variance: ((170 - 190)² + (210 - 190)²) / 2 = 400

Weighted variance after split = (1/3) × 0 + (2/3) × 400 = 266.67

Variance reduction = 280.67 - 266.67 = 14

The variance reduction is relatively small, but let's implement it anyway for this example.


#-------------------------------------------------------------------------------------#
#----------------------- Step 5: Final Decision Tree ---------------------------------#
#-------------------------------------------------------------------------------------#

Based on our calculations, here's the final decision tree:

Root (All houses, mean = $240,000)
|
|--- Size < 1700 sq ft?
|    |
|    |--- YES: Check Age
|    |    |
|    |    |--- Age < 11 years? 
|    |    |    |
|    |    |    |--- YES: Predict $200,000 (House 1)
|    |    |    |
|    |    |    |--- NO: Predict $190,000 (Houses 3, 6)
|    |
|    |--- NO: Predict $286,670 (Houses 2, 4, 5)


IF Outlook = Overcast THEN Play Tennis = Yes
IF Outlook = Sunny AND Humidity = High THEN Play Tennis = No
IF Outlook = Sunny AND Humidity = Normal THEN Play Tennis = Yes
IF Outlook = Rain AND Windy = No THEN Play Tennis = Yes
IF Outlook = Rain AND Windy = Yes THEN Play Tennis = No

#-----------------------------------------------------------------------------#
#----------------------- Making a Prediction ---------------------------------#
#-----------------------------------------------------------------------------#

Let's predict the price of a new house with:
	Size = 1400 sq ft
	Age = 7 years

Following our decision tree:
	Size < 1700 sq ft? => YES (go left)
	Age < 11 years? YES => (go left)
=> Prediction: $200,000

-----------------------

If the house had:
	Size = 1400 sq ft
	Age = 14 years
Then:
	Size < 1700 sq ft? => YES (go left)
	Age < 11 years? => NO (go right)
=> Prediction: $190,000

#-----------------------------------------------------------------#
#----------------------- Summary ---------------------------------#
#-----------------------------------------------------------------#

Key Regression Tree Principles Demonstrated
# Variance Reduction: We split nodes to minimize variance within child nodes
# Mean Value Predictions: Each leaf node predicts the mean target value of its samples
# Feature Selection: We evaluate each feature to find the best split
# Stopping Criteria: We would typically stop splitting when variance reduction is below a threshold or other stopping criteria are met