Tunning Parameters (or Tunning Hyper-Parameters) is a process to find out the most possible optimal parameters for an algorithm

For example, when building a Random Forest, some questions may come up:
# How many trees should it have (n_estimators)?
# What is the maximum number of features (max_features)?
# What is the minimum split sample size to set (min_samples_split)?
# What is the depth level to choose (max_depth)?

=> Use Tunning Parameters to find out

There are 2 sklearn modules help in Tunning Parameters
# GridSearchCV: search through all the given parameters to examine => time-consuming
# RandomizedSearchCV: pick out random given parameters to examine => faster, but can overlook some more optimized cases


#--------------------------------------------------------------------------------#
#------------------------ RandomizedSearchCV ------------------------------------#
#--------------------------------------------------------------------------------#

from sklearn import datasets
iris = datasets.load_iris()

X=data[['petal length', 'petal width']]  
y=data['species']


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 1)


# d√πng random search
from sklearn.model_selection import RandomizedSearchCV
from scipy.stats import randint as sp_randint

#parameters to check
param_dist = {"n_estimators":[30, 50, 100, 150, 200, 250, 300],
              "max_features": ['auto', 'sqrt', 'log2'],             
              "bootstrap": [True, False],
              "criterion": ["gini", "entropy"]}


from datetime import datetime
from datetime import timedelta

start_time = datetime.now()

#RandomizedSeachCV class
forest_random = RandomizedSearchCV(estimator=RandomForestClassifier(),
                                   param_distributions=param_dist,
                                   cv=5, random_state=1)

forest_random.fit(X_train,y_train)
#Each version will go through 5-fold cross validation

end_time = datetime.now()


dt = end_time - start_time
seconds_1 = (dt.days * 24 * 60 * 60 + dt.seconds) 
print(seconds_1)


#Best estimator
forest_random_best = forest_random.best_estimator_ 
print(forest_random_best)


# After the RandomizedSearchCV, the resulted model will also be the best model, so can use it to predict
y_pred_1=forest_random.predict(X_test)

