Reference link:

BernoulliNB & MultinomialNB: https://www.youtube.com/watch?v=O2L2Uv9pdDA
GaussianNB: https://www.youtube.com/watch?v=H3EjCKtlVog

#--------------------------------------------------------------------------#
#---------------- MultinomialNB OLD Formual and Principle -----------------#
#--------------------------------------------------------------------------#

Assuming we have Y as class, and X as input (text, document), we want to classify the X into class Y
=> Calculate the probability P(Y.X)

          P(Y.X) = P(Y)*P(X|Y) = P(X)*P(Y|X)
Explain:
	=> To calculate the probability where event Y and event X both occur P(Y.X)
	=> First, calculate the probability for event Y to occur P(Y)
	=> Then, calculate the probability for event X to occur after the occurrence of event A, P(X|Y)
	   (This is also the conditional probability)
	=> Then multiply P(Y)*P(X|Y), the result is P(Y.X) or P(X.Y)
	   (do the same for P(X)*P(Y|X))

If Y and X share no overlap elements, meaning they are independent each other
	=> P(X.Y) = P(X)*P(Y)


More general formula, assume X is the data with many independent elements (like a large text have many words):
	P(y1.X) = P(y1)*P(X|y1) = P(y1)*[P(x1|y1)*P(x2|y1)*P(x3|y1)*P(x4|y1)...P(xn|y1)]
	P(y2.X) = P(y2)*P(X|y2) = P(y2)*[P(x1|y2)*P(x2|y2)*P(x3|y2)*P(x4|y2)...P(xn|y2)]



############### Calculate the P(y_i | x_i) #####################################

           --------------------------------------------------
	  |	P(y_i | x_i) =  count(x_i | y_i) / Tc_y_i    |
           --------------------------------------------------

# count(x_i | y_i) = the number of words x_i existing in class y_i
# Tc_y_i           = the total number of all words existing in class y_i


#################### Training/Fitting and Predicting ##############################

So, when fitting the data into model, we will calculate the P(y1|X) and P(y2|X) probabilities

Then when the new input comes up (X_new), we will calculate the ouput is P(y1.X_new) and P(y2.X_new)

=> The P(y1.X_new) is the probability of observation X_new belong to class y1
   The P(y2.X_new) is the probability of observation X_new belong to class y2
   (and so on if have more classes)

After calculating the P(y1.X_new) and P(y2.X_new), we compare which one is higher
=> For example if P(y2.X_new) > P(y1.X_new), then we will classify the X_new into class y2



#------------------------------------------------------#
#---------------- Example OLD formual -----------------#
#------------------------------------------------------#

Given a text data with label like this:

	Id	Text				banhbo    banhgio    buncha    chaolong    hanoi     hutiu    omai    pho   saigon      Class       
	1	"hanoi pho chaolong hanoi"     	   0	     0	       0           1         2         0        0      1      0         mien_Bac
	2	"hanoi buncha pho omai"		   0	     0         1           0         1         0        1      1      0         mien_Bac
	3	"pho banhgio omai"                 0         1         0           0         0         0        1      1      0         mien_Bac 
	4	"saigon hutiu banhbo pho"          1         0         0           0         0         1        0      1      1         mien_Nam


We have ouput 2 classes:
	+y1 = "mien_Bac"     => P(y1) = 3/4 = 0.75
	+y2 = "mien_Nam"     => P(y2) = 1/4 = 0.25

We have total number of words in:
	+class y1 = "mien_Bac":  Tc_y1 = count_text1 + count_text2 + count_text3 = 4 + 4 + 3 = 11
	+class y1 = "mien_Nam":  Tc_y2 = count_tex3                                          = 4


We have input X:
	+x1 = "banhbo"         => P(x1|y1) = count(x1|y1) / Tc_y1 = (0+0+0)/11 = 0
				  P(x1|y2) = count(x1|y2) / Tc_y2 = 1/4        = 1/4

	+x2 = "banhgio"        => P(x2|y1) = count(x2|y1) / Tc_y1 = (0+0+1)/11 = 1/11
				  P(x2|y2) = count(x2|y2) / Tc_y2 = 0/4        = 0
	
	+x3 = "buncha"	       => P(x3|y1) = count(x3|y1) / Tc_y1 = (0+1+0)/11 = 1/11
				  P(x3|y2) = count(x3|y2) / Tc_y2 = 1/4        = 0

	+x4 = "chaolong"       => P(x4|y1) = count(x4|y1) / Tc_y1 = (1+0+0)/11 = 1/11
				  P(x4|y2) = count(x4|y2) / Tc_y2 = 0/4        = 0

	+x5 = "hanoi"          => P(x5|y1) = count(x5|y1) / Tc_y1 = (2+1+0)/11 = 3/11
				  P(x5|y2) = count(x5|y2) / Tc_y2 = 0/4        = 0

	+x6 = "hutiu"          => P(x6|y1) = count(x6|y1) / Tc_y1 = (0+0+0)/11 = 0
				  P(x6|y2) = count(x6|y2) / Tc_y2 = 1/4        = 1/4

	+x7 = "omai"           => P(x7|y1) = count(x7|y1) / Tc_y1 = (0+1+1)/11 = 2/11
				  P(x7|y2) = count(x7|y2) / Tc_y2 = 0/4        = 0

	+x8 = "pho"	       => P(x8|y1) = count(x8|y1) / Tc_y1 = (1+1+1)/11 = 3/11
				  P(x8|y2) = count(x8|y2) / Tc_y2 = 1/4        = 1/4

	+x9 = "saigon"         => P(x9|y1) = count(x9|y1) / Tc_y1 = (0+0+0)/11 = 0
				  P(x9|y2) = count(x9|y2) / Tc_y2 = 1/4        = 1/4 


Now, if we have a new_text like this "hanoi buncha buncha pho"
=> Calculate: P(new_text . y1) = P(y1) * P("hanoi"|y1) * P("buncha"|y1)^2 * P("pho"|y1)
			       = P(y1) * P(x5|y1)      * P(x3|y1)^2       * P(x8|y1)
			       = 0.75  * (3/11)        * (1/11)^2         * (3/11)
			       = 0.00046103408


=> Calculate: P(new_text . y2) = P(y2) * P("hanoi"|y2) * P("buncha"|y2)^2 * P("pho"|y2)
			       = P(y2) * P(x5|y2)      * P(x3|y2)^2       * P(x8|y2)
			       = 0.25  * 0             * (0^2)            * 1/4
			       = 0

Since the P(new_text . y1) >  P(new_text . y2)
=> We classify the new_text as class y1 or "mien_Bac"

#To avoid too small number => use ln(P(x_i . y_i)), then compare which one is higher to classify


PROBLEM:
	+Whenever a text has word "saigon" => P(text | "mien_Bac") = 0
			          "hanoi"  => P(text | "mien_Nam") = 0

	+This is due to the fact that in training set, no "mien_Bac" text has word "saigon"
                                                   and no "mien_Nam" text has word "hanoi"


=> To avoid the probability becomes 0, see the following part:	MultinomialNB NEW formula